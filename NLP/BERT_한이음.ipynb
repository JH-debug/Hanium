{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "BERT 한이음.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4GwVrv3RbDEh"
      },
      "source": [
        "# We will use the official tokenization script created by the Google team\n",
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBtRRJ04cNF0",
        "outputId": "16c73d64-c850-4c8e-f174-e8f4d7d0bfe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "ysPksUKnbDEk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import tokenization"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7csRyp-bDEm"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z58kExLkbDEm"
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=40):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNftRrpLD-si"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "    \n",
        "    # return a single tensor value\n",
        "    return _f1score"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "aAObzxpebDEp"
      },
      "source": [
        "def build_model(bert_layer, max_len=40):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(12, activation='softmax')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=1e-6), loss='categorical_crossentropy', metrics=['acc'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr45sCJebDEr"
      },
      "source": [
        "# Load and Preprocess\n",
        "\n",
        "- Load BERT from the Tensorflow Hub\n",
        "- Load CSV files containing training data\n",
        "- Load tokenizer from the bert layer\n",
        "- Encode the text into tokens, masks, and segment flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8AFUY8vXbDEr",
        "outputId": "cbc4d61e-bb02-471d-d7a6-68d42744d47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11.8 s, sys: 2.54 s, total: 14.4 s\n",
            "Wall time: 14.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwiV-FvYi6ES"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSgGRuvBcXMR",
        "outputId": "17c1c3cc-7f46-422c-deb5-0be8d7486225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M195v8mScdju",
        "outputId": "66d96603-9412-4369-8849-334b719094a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 프로젝트\n",
            "'증상 발화데이터 메타 (1).csv'\n",
            "'2020 공모전 제출서식 및 참고자료_파일.zip'\n",
            "'[서울-2반-8조] 2차 산출물 제출 건.hwp'\n",
            "'(서울-2반-8조) 발표자료.pdf'\n",
            "'[서울-2반-8조] 발표 PPT 초안.pdf'\n",
            "'(서울-2반-8조) 발표자료.pptx'\n",
            "'증상 발화데이터 메타 (2).csv'\n",
            "'(서울 2반 - 홍윤표) 전기차.zip'\n",
            "'(서울 2반_홍윤표) 민원분석.zip'\n",
            "'(서울2반_홍윤표) 관광분석.zip'\n",
            " 3-min-pytorch-master\n",
            " %5B%EC%B2%A8%EB%B6%80%5D+2020%EB%85%84+%ED%95%98%EB%B0%98%EA%B8%B0+%EA%B8%80%EB%A1%9C%EB%B2%8C%EA%B3%BC%EC%A0%95+%EC%97%B0%EC%88%98%EC%97%85%EC%B2%B4+%ED%98%84%ED%99%A9.xlsx.exe\n",
            " ADV\n",
            "'BERT 감성분석 모델.ipynb'\n",
            " BiLSTM.ipynb\n",
            " boaz_study\n",
            "'Colab Notebooks'\n",
            "'복부 발화데이터.csv'\n",
            "'증상 발화데이터 메타.csv'\n",
            "'증상 발화데이터.csv'\n",
            "'하이닥 데이터 전처리.csv'\n",
            "'하이닥 데이터.csv'\n",
            " dacon\n",
            "'제목 없는 스프레드시트.gsheet'\n",
            " mnist_assignment.ipynb\n",
            " model.h5\n",
            " 출석체크.png\n",
            " 작업관리자.png\n",
            "'Pytorch DNN.ipynb'\n",
            "'pytorch tutorial'\n",
            "'Resume Template 5의 사본 (1).gdoc'\n",
            "'Resume Template 5의 사본 (2).gdoc'\n",
            "'Resume Template 5의 사본.gdoc'\n",
            " soynlp.model\n",
            " Untitled\n",
            "'Untitled (1)'\n",
            "'Untitled (2)'\n",
            " w2v\n",
            " word2vec\n",
            " wordnet.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yYu7n0ZLbDEu"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/증상 발화데이터 메타 (2).csv\", encoding = 'cp949')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO7D9KYftgsU"
      },
      "source": [
        "data = data.sample(frac = 1, axis = 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o34Hny74rYPw",
        "outputId": "af0423aa-232a-4e81-f34a-9e9e276f2de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "data['병명'].unique()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['위염', '장염', '비염', '간염', '축농증', '중이염', '구내염', '고막염', '외이도염', '질염',\n",
              "       '방광염', '다낭성 난소 증후군'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgYgtjJq1W6z"
      },
      "source": [
        "data.reset_index(drop = True, inplace = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zAY5UwdZ7Ar",
        "outputId": "ecdc79d8-8bbe-4fd2-b79a-6a1995b3f658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17302, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ofX95nn3cfa"
      },
      "source": [
        "data[\"증상질문\"] = data[\"증상질문\"].astype(\"string\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AZ_D1-haY6m"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "encoder.fit(data['병명'])\n",
        "data['병명'] = encoder.transform(data['병명'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZslSohrCp-d",
        "outputId": "91fcc3a8-f199-405f-dfa5-4f840f3f74fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "mapping = dict(zip( range(len(encoder.classes_)), encoder.classes_))\n",
        "mapping"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '간염',\n",
              " 1: '고막염',\n",
              " 2: '구내염',\n",
              " 3: '다낭성 난소 증후군',\n",
              " 4: '방광염',\n",
              " 5: '비염',\n",
              " 6: '외이도염',\n",
              " 7: '위염',\n",
              " 8: '장염',\n",
              " 9: '중이염',\n",
              " 10: '질염',\n",
              " 11: '축농증'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTyCj2I7pWTo"
      },
      "source": [
        "train_labels = data['병명'].values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfajXmWYdFIT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from keras import utils\n",
        "train = data.drop(\"병명\", axis = 1)\n",
        "train_labels = utils.to_categorical(train_labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DxDV2IsTbDEz"
      },
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHtu12m1LZvk"
      },
      "source": [
        "data.dropna(axis = 0, inplace = True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "G2zwhspubDE1"
      },
      "source": [
        "train_input = bert_encode(data[\"증상질문\"].values, tokenizer, max_len=40)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Niuojn9BbDE2"
      },
      "source": [
        "# Model: Build, Train, Predict, Submit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HUbjlOlCbDE3",
        "outputId": "26312297-73d8-46c9-f1bd-8a6b50fcccdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "model = build_model(bert_layer, max_len=40)\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 40)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 12)           12300       tf_op_layer_strided_slice[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 335,154,189\n",
            "Trainable params: 335,154,188\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vXssFG8_bDE5",
        "outputId": "89db07f4-00ca-4013-e04c-e1daeba87240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/final_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "train_history = model.fit(\n",
        "    train_input, train_labels,\n",
        "    validation_split=0.3,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint],\n",
        "    batch_size=16\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "757/757 [==============================] - 477s 630ms/step - loss: 0.7499 - acc: 0.7725 - val_loss: 0.2633 - val_acc: 0.9291\n",
            "Epoch 2/5\n",
            "757/757 [==============================] - 479s 633ms/step - loss: 0.1717 - acc: 0.9495 - val_loss: 0.1113 - val_acc: 0.9667\n",
            "Epoch 3/5\n",
            "757/757 [==============================] - 479s 633ms/step - loss: 0.0879 - acc: 0.9750 - val_loss: 0.0764 - val_acc: 0.9792\n",
            "Epoch 4/5\n",
            "757/757 [==============================] - 478s 632ms/step - loss: 0.0563 - acc: 0.9841 - val_loss: 0.0501 - val_acc: 0.9865\n",
            "Epoch 5/5\n",
            "757/757 [==============================] - 477s 630ms/step - loss: 0.0416 - acc: 0.9879 - val_loss: 0.0415 - val_acc: 0.9875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCpZZAp5FkUY"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/final_model.h5')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2htqSjkhewW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcnORHifCDQ7"
      },
      "source": [
        "test = pd.DataFrame(['테스트문장'], columns = ['증상'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTqkkTQoCJWy"
      },
      "source": [
        "test_input = bert_encode(test['증상'].values, tokenizer, max_len=40)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_7khF4UetW4",
        "outputId": "0d236c0d-b304-4123-a839-c74bcce23fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pred = model.predict(test_input)\n",
        "mapping[np.where(pred[0] == pred[0].max())[0][0]]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'위염'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ0xYFFgOaLR",
        "outputId": "6c356927-0004-41c1-c494-c3ba9fef1b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred[0].max()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.80330306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEAvGdYcuu-t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}